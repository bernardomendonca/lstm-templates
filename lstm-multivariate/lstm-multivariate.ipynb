{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "def parse(x):\n",
    "    return datetime.strptime(x, '%Y %m %d %H')\n",
    "dataset = read_csv('raw.csv', parse_dates= [['year', 'month', 'day', 'hour']], index_col=0, date_parser=parse)\n",
    "# Droping column 'No'\n",
    "dataset.drop('No',axis=1,inplace=True)\n",
    "# Specifiying column names\n",
    "dataset.columns = ['pollution', 'dew','temp','press','wnd_dir','wnd_spd','snow','rain']\n",
    "dataset.index.name = 'date'\n",
    "# Markinng NaN values as 0\n",
    "dataset['pollution'].fillna(0,inplace=True)\n",
    "# drop the first 24 hours\n",
    "dataset = dataset[24:]\n",
    "# checking the head\n",
    "print(dataset.head(5))\n",
    "# saving as CSV\n",
    "dataset.to_csv('pollution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the new dataset\n",
    "dataset = read_csv('pollution.csv', header=0,index_col=0)\n",
    "values = dataset.values\n",
    "#specifying columns to plot\n",
    "# not plotting wind direction (wnd_dir) (column 4) since its categorical\n",
    "groups = [0,1,2,3,5,6,7]\n",
    "i = 1\n",
    "# plot each plot\n",
    "pyplot.figure()\n",
    "for group in groups:\n",
    "    pyplot.subplot(len(groups), 1, i)\n",
    "    pyplot.plot(values[:, group])\n",
    "    pyplot.title(dataset.columns[group], y=0.5, loc='right')\n",
    "    i += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encoder (that's for the wind direction)\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "\n",
    "#ensuring is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalizing values\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# Framing as supervised learning\n",
    "reframed = series_to_supervised(scaled,1,1)\n",
    "\n",
    "# drop columns t+n since we only want to predict t\n",
    "reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the reframed dataset into train and test\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training:\n",
    "# for X: Getting all the TRAIN rows and all but the last column\n",
    "# for Y: Getting all the TRAIN rows and the last column\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "# For testing:\n",
    "# for X: Getting all the TEST rows and all but the last column\n",
    "# for Y: Getting all the TEST rows and the last column\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.shape(test_X))\n",
    "\n",
    "print((train_X.shape[1], train_X.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# Inverting scale for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:,1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# Inverting scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:,1:]), axis=1)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculating RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y,inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bdcc8738350348f5da3cd958a6f31e3755dac4740b3163f526dc5114836e977f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
